# -*- coding: utf-8 -*-
"""Sentence_Extraction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19uPKS09J-64GO9md70SvUNnqkD05ujy4
"""

import nltk
import random
nltk.download('punkt')
nltk.download('gutenberg')
from nltk.corpus import gutenberg
import pandas as pd
import regex as re
import string

def labelling(df):
  df = pd.read_csv('Gutenberg_Sentence_Extract.csv')
  group_book_name = df.groupby('Book Name')
  label_alphabets = {i: letter for i, letter in enumerate(string.ascii_lowercase)}
  df['Label'] = pd.factorize(df['Book Name'])[0]
  df['Label'] = df['Label'].replace(label_alphabets)
  df.to_csv('Gutenberg_Sentence_Extract.csv', index=False)
  return df

df = pd.DataFrame(columns=['Book Name', 'Sentence'])
for i in range(0,200):
  sentence=''
  full_book_ids = gutenberg.fileids()
  random_book = random.choice(full_book_ids)
  book_name = random_book.replace('.txt','')
  book_full_text = gutenberg.raw(random_book)
  split_word = re.split('\s',book_full_text)
  length = len(split_word)
  range1 = random.randint(0, length-105)
  range2 = range1 + 105
  for a in range(range1, range2):
    sentence+=' '+split_word[a]
  book_sentence = {'Book Name': book_name, 'Sentence': sentence}
  df=df.dropna(axis=1, thresh=1)
  df=df.append(book_sentence,ignore_index=True)
df.to_csv('Gutenberg_Sentence_Extract.csv', index=False)
labelling(df)

